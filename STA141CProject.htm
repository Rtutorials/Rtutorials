<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=macintosh">
<meta name=Generator content="Microsoft Word 14 (filtered)">
<style>
<!--
 /* Font Definitions */
@font-face
	{font-family:Arial;
	panose-1:2 11 6 4 2 2 2 2 2 4;}
@font-face
	{font-family:"Courier New";
	panose-1:2 7 3 9 2 2 5 2 4 4;}
@font-face
	{font-family:"Courier New";
	panose-1:2 7 3 9 2 2 5 2 4 4;}
@font-face
	{font-family:"Lucida Grande";
	panose-1:2 11 6 0 4 5 2 2 2 4;}
 /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0in;
	margin-bottom:.0001pt;
	line-height:115%;
	font-size:11.0pt;
	font-family:Arial;
	color:black;}
h1
	{margin-top:20.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:20.0pt;
	font-family:Arial;
	color:black;
	font-weight:normal;}
h2
	{margin-top:.25in;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:16.0pt;
	font-family:Arial;
	color:black;
	font-weight:normal;}
h3
	{margin-top:16.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:14.0pt;
	font-family:Arial;
	color:#434343;
	font-weight:normal;}
h4
	{margin-top:14.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:12.0pt;
	font-family:Arial;
	color:#666666;
	font-weight:normal;}
h5
	{margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:11.0pt;
	font-family:Arial;
	color:#666666;
	font-weight:normal;}
h6
	{margin-top:12.0pt;
	margin-right:0in;
	margin-bottom:4.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:11.0pt;
	font-family:Arial;
	color:#666666;
	font-weight:normal;
	font-style:italic;}
p.MsoTitle, li.MsoTitle, div.MsoTitle
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:3.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:26.0pt;
	font-family:Arial;
	color:black;}
p.MsoSubtitle, li.MsoSubtitle, div.MsoSubtitle
	{margin-top:0in;
	margin-right:0in;
	margin-bottom:16.0pt;
	margin-left:0in;
	line-height:115%;
	font-size:15.0pt;
	font-family:Arial;
	color:#666666;}
p.MsoAcetate, li.MsoAcetate, div.MsoAcetate
	{margin:0in;
	margin-bottom:.0001pt;
	font-size:9.0pt;
	font-family:"Lucida Grande","serif";
	color:black;}
p.normal, li.normal, div.normal
	{margin:0in;
	margin-bottom:.0001pt;
	line-height:115%;
	font-size:11.0pt;
	font-family:Arial;
	color:black;}
span.BalloonTextChar
	{font-family:"Lucida Grande","serif";}
.MsoChpDefault
	{font-size:11.0pt;
	font-family:Arial;
	color:black;}
.MsoPapDefault
	{line-height:115%;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:1.0in 1.0in 1.0in 1.0in;}
div.WordSection1
	{page:WordSection1;}
-->
</style>

</head>

<body bgcolor=white lang=EN-US>

<div class=WordSection1>

<p class=MsoTitle><a name="_zd6lmaubj2kq"></a>Run times for SVM image
recognition using dimensionality reduction</p>

<p class=MsoSubtitle><a name="_npbmfehmfuet"></a>by Ben Hendel and Russell
Luttrell </p>

<p class=normal><span><img width=275 height=80 id=image9.png
src="STA141CProject_files/image001.gif"></span></p>

<p class=normal style='text-indent:.5in'><span style='font-family:"Times New Roman"'>The
famous MNIST dataset includes 70,000 images of hand drawn digits for
classification into the numbers 0-9. Each 28 by 28 image is a matrix of values
that can be anywhere from 0 to 255 depending on how dark the cell is. While
there are many different ways of classifying this data, we are going to be
looking at Support Vector Machines (SVMs) in particular. SVMs create a boundary
by maximizing the margin between points, and use a kernel to represent the data
in higher dimensions to create a classifier between points that would not
otherwise be linearly separable. </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>SVM is relatively
fast, but Scikit-learn’s svm.SVC function may be unnecessarily slow for a
multiple classification problem. SVM is normally built to create a boundary
between two different classes (binary classification). For a problem like
classifying digits into 10 categories, this doesn’t work. What Scikit-learn
does to get around this is to do many “one vs. one” classifications, yielding
n(n-1)/2 = 45 different combinations. For example, is it a 5 or a 7, 8 or a 9,
etc. This makes it very time intensive to run on all 70,000 images (<span
style='background:white'>478.48</span></span><span style='font-size:10.5pt;
line-height:115%;font-family:"Times New Roman";background:white'> seconds)</span><span
style='font-family:"Times New Roman"'>. For our analysis, we are looking to find
a way to speed up SVM. This will likely result in some loss of accuracy, but is
necessary for applications with millions of data points. In our analysis, we
will select a subset of 10,000 rows of data and run various procedures to speed
up the SVM. </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>Baseline SVM</span></b></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal style='text-indent:.5in'><span style='font-family:"Times New Roman"'>The
time complexity of sklearn.svm.SVC is more than quadratic with respect to the
number of samples[3].&nbsp; By executing an SVM with different sized subsets of
the original 70,000 data points, we can observe the time it takes.&nbsp; When
we plotted time vs number of samples, the resulting plot looked somewhat
quadratic.</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span><img width=314 height=236 id=image6.png
src="STA141CProject_files/image002.gif"></span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>Increasing the size
of our training subset generally improves the performance of our model, though
not always since the selection is random. </span></p>

<p class=normal><span><img width=344 height=259 id=image7.png
src="STA141CProject_files/image003.gif"></span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>Support Vector
Machines involve a number of hyperparameters.&nbsp; These include the kernel
function to pick, the regularization parameter C, the parameter gamma of the
kernel, and the degree in the case of a polynomial kernel.&nbsp; To determine
the best settings for these parameters for the rbf kernel, we tested all
combinations of different values on a logarithmic scale from 10^-3 to
10^3.&nbsp; By doing a grid search (trying out combinations of gammas and Cs)
we are able to find the best values for the parameters of gamma and C.&nbsp; Of
the values for gamma and C that we tested, the best results were from gamma =
.01 and C = 10.&nbsp; We achieved 95.48% accuracy with the Gaussian rbf kernel
with these values of gamma and C.&nbsp; We used these values of gamma and C for
the rest of our SVM uses.</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span><img width=470 height=353 id=image10.png
src="STA141CProject_files/image004.gif"></span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>Starting with a
baseline RBF kernel SVM on a random set of 10000 data points, we get an
accuracy of 0.9527 in 25.51 seconds. Various other kernels were tried, giving
mixed results.</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>Kernel &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;Time
(seconds)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Accuracy</span></b></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>&nbsp;</span></b></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>RBF&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></i><span
style='font-family:"Times New Roman"'>25.51&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.953&nbsp;&nbsp;
</span></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>Sigmoid&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></i><span
style='font-family:"Times New Roman"'>25.29&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.889</span></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>Polynomial
degree 2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></i><span
style='font-family:"Times New Roman"'>23.20&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.948</span></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>Polynomial
degree 3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></i><span
style='font-family:"Times New Roman"'>29.76&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.935&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>Polynomial
degree 4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></i><span
style='font-family:"Times New Roman"'>37.55&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.898</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal style='text-indent:.5in'><span style='font-family:"Times New Roman"'>Using
a Sigmoid kernel on that same set of data gives us accuracy of 0.889 in 25.29
seconds. A Polynomial kernel with degree 2 gets accuracy 0.948 in 23.20
seconds; and with a degree of 3: 0.935 in 29.76 seconds. Going beyond degree 3
into degree 4 is a bad idea, as the runtime goes up to 37.55 seconds and
accuracy goes down to 0.898. This is likely due to overfitting, because the
training accuracy was 0.9295. Increasing the degree further only broadens this
difference. Runtime seems to increase with the degree of the polynomial, and
fitting a higher order polynomial can create too many overfitted boundaries. In
any case, polynomial kernels do not perform as well as the RBF in our
application. </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>Linear SVC</span></b></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal style='text-indent:.5in'><span style='font-family:"Times New Roman"'>Scikit-learn
also includes a “LinearSVC” function which uses liblinear instead of libsvm,
and works on a “one vs rest” rather than “one vs one” basis. A basic LinearSVC
runs in only 0.75 seconds, which is several times faster. The accuracy,
however, is only 0.903 (with an iteratively maximized C = 0.02).&nbsp; From the
baseline rbf SVM, we lose 5% accuracy but it takes 1/33 of the time to run.
Theoretically, increasing C should soften the margin-maximizing rule if it
means more correct classification. By playing around with different values of
C, the opposite seems to be the case. Decreasing C seems to increase accuracy
and precision, while decreasing the runtime.</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>This method is fast
enough that it can be run on all 70,000 rows in 9.53 seconds with 0.91 accuracy
and precision. The time is saved because instead of doing 45 comparisons (each
potential digit vs each other potential digit), they only do 10. For example, Is
it a three vs is it not a three? </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>Principal
Components</span></b></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal style='text-indent:.5in'><span style='font-family:"Times New Roman"'>Principal
Components Analysis is a widely used dimensional reduction technique where
orthogonal linear combinations of variables are taken to maximize the
proportion of variance explained. With our data, we can trim down to 20
components and preserve 64.5% of the variance. Trimming down to 50 components
preserves 82.7% of the variance. The relationship is summarized in the
screeplot of variance below.</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span><img width=306 height=202 id=image11.png
src="STA141CProject_files/image005.gif"></span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>Each additional
component is less useful, and there is no clear “elbow” in the graph that tells
us when we have chosen enough components. Hopefully, this dimensionality
reduction will make the SVM run faster without compromising too much in
accuracy. </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span><img width=311 height=201 id=image12.png
src="STA141CProject_files/image006.gif"></span></p>

<p class=normal><span style='font-family:"Times New Roman"'>Running an SVM on
10,000 rows of the reduced data runs in an astonishingly fast 1.9 seconds and
gives an accuracy and precision of 0.94, which is almost as good as the
baseline accuracy of 0.9527 but taking 12 times less time.</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>If we are to reduce
the number of components, accuracy is lost and not much time is saved; 10
components drops accuracy down to 0.87 while saving less than a second of time.
If we are to increase the number of components, we notice that accuracy
plateaus at around 0.943, meaning there is little to be gained from adding
components. The exact number of components you choose is up to interpretation,
but anywhere between 30 and 70 runs in 1.5-2 seconds and achieves accuracy of
0.93-0.94. </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>This method also
takes time to fit the PCA on the training set. This is negligible with our
chunk of 10,000, but may be significant when applied to the whole dataset.
Running a 30-component PCA SVM on the whole dataset takes <span
style='background:white'>27.4 seconds for PCA fitting and another 43.2 seconds
for the SVM, with an accuracy of 0.968.&nbsp; </span></span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>&nbsp;</span></b></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>Conclusion</span></b></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>Method&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Time
(seconds)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
Accuracy</span></b></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>&nbsp;</span></i></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>SVM (rbf kernel)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span
style='background:white'>478.48&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
0.981</span></span></i></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span
style='background:white'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></i></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>LinearSVC&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;
0.914</span></i></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>&nbsp;</span></i></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>PCA SVM (30
principal components)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 68.70&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;
0.968</span></i></p>

<p class=normal><i><span style='font-family:"Times New Roman"'>&nbsp;</span></i></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>&nbsp;</span></b></p>

<p class=normal><b><span style='font-family:"Times New Roman"'>&nbsp;</span></b></p>

<p class=normal style='text-indent:.5in'><span style='font-family:"Times New Roman"'>Three
of the best techniques are summarized above. Which one is the best trade-off
between time and accuracy? </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>It depends on how
much you value time and accuracy, and also on the size of the data you are
working with. Scikit-learn’s default svm.SVC function is a solid and accurate
tool for most uses, and its rbf kernel performs very well at classifying
hand-drawn digits. However, if you are willing to sacrifice accuracy for time,
LinearSVC is many times faster and the better choice. A PCA is extremely fast
and accurate for moderately sized data, but takes a while to reduce very large
datasets. </span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>All these methods
to reduce runtime are on the machine learning side; what has not been mentioned
are data cleanup and processing techniques such as deskewing, rotating, and
filtering, which have the potential to greatly improve the SVM. Some of
professor Yann LeCun’s papers are able to achieve accuracy greater than 99%[1].
</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>-some of the code that was used in our project-</p>

<p class=normal>&nbsp;</p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>from __future__ import division</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import matplotlib.pyplot as plt</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import random </span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import numpy as np</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>from sklearn import datasets, svm, metrics</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import sklearn</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>from sklearn.model_selection import train_test_split</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>mnist = datasets.fetch_mldata(&quot;MNIST Original&quot;)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>r = list(range(70000))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>np.random.seed(seed=37)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>np.random.shuffle(r)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>X,y = mnist.data/255, mnist.target</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>xtrain, xtest, ytrain, ytest = train_test_split(X, y,
test_size=0.33, random_state=41)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import time</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>start = time.time()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'># Create a classifier: a support vector classifier</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>classifier = svm.SVC(gamma = 0.01, C = 10)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>classifier.fit(xtrain, ytrain)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>expected = ytest</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>predicted = classifier.predict(xtest)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>end = time.time()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>print(end - start)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>print(&quot;Classification report for classifier %s:\n%s\n&quot;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; % (classifier,
metrics.classification_report(expected, predicted)))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>print(&quot;Confusion matrix:\n%s&quot; %
metrics.confusion_matrix(expected, predicted))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>print(sklearn.metrics.accuracy_score(expected, predicted))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>from sklearn import decomposition</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import numpy as np</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import matplotlib</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>import matplotlib.pyplot as plt</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>start = time.time()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>pca = decomposition.PCA(n_components=30, svd_solver='full')</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>pca.fit(xtrain)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>pxtrain = pca.fit_transform(xtrain)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>pxtest = pca.transform(xtest)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>end = time.time()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>print(end - start)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>plt.scatter(range(30), pca.explained_variance_ratio_)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>plt.title(&quot;Proportion of Variance Explained with nth
Eigenvalue&quot;)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>plt.show()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>def SVMtime(inxtrain, inytrain, inxtest, inytest, gamma = 0.01,
C = 1):</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; start = time.time()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; # Create a classifier: a support vector
classifier</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; classifier = svm.SVC(gamma = gamma, C = C)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; classifier.fit(inxtrain, inytrain)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; expected = inytest</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; predicted = classifier.predict(inxtest)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; end = time.time()</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; print(end - start)</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; print(&quot;Classification report for
classifier %s:\n%s\n&quot;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; % (classifier,
metrics.classification_report(expected, predicted)))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; print(&quot;Confusion matrix:\n%s&quot; %
metrics.confusion_matrix(expected, predicted))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; print(&quot;Variance explained&quot;,
sum(pca.explained_variance_ratio_))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;&nbsp;&nbsp; print(&quot;Accuracy&quot;,
sklearn.metrics.accuracy_score(expected, predicted))</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>&nbsp;</span></p>

<p class=normal><span style='font-size:10.0pt;line-height:115%;font-family:
"Courier New"'>SVMtime(pxtrain, ytrain, pxtest, ytest)</span></p>

<p class=normal>&nbsp;</p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>References<br>
<br>
</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>1.“THE MNIST
DATABASE of handwritten digits” Yann LeCun, 1998 http://yann.lecun.com/exdb/mnist/</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>2.“Understanding
SVMs for Digit Classification using MNIST Dataset” Vijayasaradhi Indurthi, </span><span
style='font-size:11.5pt;line-height:115%;font-family:"Times New Roman"'>November
26, 2015</span></p>

<p class=normal><a
href="https://www.linkedin.com/pulse/understanding-svms-digit-classification-using-mnist-dataset-indurthi"><span
style='font-family:"Times New Roman";color:#1155CC'>https://www.linkedin.com/pulse/understanding-svms-digit-classification-using-mnist-dataset-indurthi</span></a></p>

<p class=normal><span style='font-family:"Times New Roman"'>&nbsp;</span></p>

<p class=normal><span style='font-family:"Times New Roman"'>3.“sklearn.svm.SVC¶”
Scikit Learn 2016</span></p>

<p class=normal><a
href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"><span
style='font-family:"Times New Roman";color:#1155CC'>http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html</span></a></p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

<p class=normal>&nbsp;</p>

</div>

</body>

</html>
